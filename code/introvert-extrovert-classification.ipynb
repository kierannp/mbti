{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task for Today  \n",
    "\n",
    "***\n",
    "\n",
    "## Personality Type Prediction  \n",
    "\n",
    "Given *data about posts people have made*, let's try to predict the **personality type** of a given person.  \n",
    "  \n",
    "We will use a TensorFlow RNN to make our predictions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Getting Started"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('data/mbti_1.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 8675 entries, 0 to 8674\n",
      "Data columns (total 2 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   type    8675 non-null   object\n",
      " 1   posts   8675 non-null   object\n",
      "dtypes: object(2)\n",
      "memory usage: 135.7+ KB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['INFJ', 'ENTP', 'INTP', 'INTJ', 'ENTJ', 'ENFJ', 'INFP', 'ENFP',\n",
       "       'ISFP', 'ISTP', 'ISFJ', 'ISTJ', 'ESTP', 'ESFP', 'ESTJ', 'ESFJ'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['type'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_inputs(df):\n",
    "    \n",
    "    texts = df['posts'].copy()\n",
    "    labels = df['type'].copy()\n",
    "    \n",
    "    # Process text data\n",
    "    stop_words = stopwords.words('english')\n",
    "    \n",
    "    texts = [text.lower() for text in texts]\n",
    "    texts = [text.split() for text in texts]\n",
    "    texts = [[word.strip() for word in text] for text in texts]\n",
    "    texts = [[word for word in text if word not in stop_words] for text in texts]\n",
    "    \n",
    "    vocab_length = 10000\n",
    "    \n",
    "    tokenizer = Tokenizer(num_words=vocab_length)\n",
    "    tokenizer.fit_on_texts(texts)\n",
    "    \n",
    "    texts = tokenizer.texts_to_sequences(texts)\n",
    "    \n",
    "    max_seq_length = np.max([len(text) for text in texts])\n",
    "    \n",
    "    texts = pad_sequences(texts, maxlen=max_seq_length, padding='post')\n",
    "    \n",
    "    # Process label data\n",
    "    label_values = [\n",
    "        'INFJ', 'ENTP', 'INTP', 'INTJ', 'ENTJ', 'ENFJ', 'INFP', 'ENFP',\n",
    "       'ISFP', 'ISTP', 'ISFJ', 'ISTJ', 'ESTP', 'ESFP', 'ESTJ', 'ESFJ'\n",
    "    ]\n",
    "    \n",
    "    label_mapping = {label: np.int(label[0] == 'E') for label in label_values}\n",
    "    \n",
    "    labels = labels.replace(label_mapping)\n",
    "    labels = np.array(labels)\n",
    "    \n",
    "    return texts, labels, max_seq_length, vocab_length, label_mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"'http://www.youtube.com/watch?v=qsxhcwe3krw|||http://41.media.tumblr.com/tumblr_lfouy03pma1qa1rooo1_500.jpg|||enfp\", 'intj', 'moments', 'https://www.youtube.com/watch?v=iz7le1g4xm4', 'sportscenter', 'top', 'ten', 'plays', 'https://www.youtube.com/watch?v=ucdfze1etec', 'pranks|||what', 'life-changing', 'experience', 'life?|||http://www.youtube.com/watch?v=vxzeywwrdw8', 'http://www.youtube.com/watch?v=u8ejam5dp3e', 'repeat', 'today.|||may', 'perc', 'experience', 'immerse', 'you.|||the', 'last', 'thing', 'infj', 'friend', 'posted', 'facebook', 'committing', 'suicide', 'next', 'day.', 'rest', 'peace~', 'http://vimeo.com/22842206|||hello', 'enfj7.', 'sorry', 'hear', 'distress.', 'natural', 'relationship', 'perfection', 'time', 'every', 'moment', 'existence.', 'try', 'figure', 'hard', 'times', 'times', 'growth,', 'as...|||84389', '84390', 'http://wallpaperpassion.com/upload/23700/friendship-boy-and-girl-wallpaper.jpg', 'http://assets.dornob.com/wp-content/uploads/2010/04/round-home-design.jpg', '...|||welcome', 'stuff.|||http://playeressence.com/wp-content/uploads/2013/08/red-red-the-pokemon-master-32560474-450-338.jpg', 'game.', 'set.', 'match.|||prozac,', 'wellbrutin,', 'least', 'thirty', 'minutes', 'moving', 'legs', '(and', 'mean', 'moving', 'sitting', 'desk', 'chair),', 'weed', 'moderation', '(maybe', 'try', 'edibles', 'healthier', 'alternative...|||basically', 'come', 'three', 'items', 'determined', 'type', '(or', 'whichever', 'types', 'want', 'do)', 'would', 'likely', 'use,', 'given', \"types'\", 'cognitive', 'functions', 'whatnot,', 'left', 'by...|||all', 'things', 'moderation.', 'sims', 'indeed', 'video', 'game,', 'good', 'one', 'that.', 'note:', 'good', 'one', 'somewhat', 'subjective', 'completely', 'promoting', 'death', 'given', 'sim...|||dear', 'enfp:', 'favorite', 'video', 'games', 'growing', 'now,', 'current', 'favorite', 'video', 'games?', ':cool:|||https://www.youtube.com/watch?v=qypqt8umzmy|||it', 'appears', 'late.', \":sad:|||there's\", 'someone', 'everyone.|||wait...', 'thought', 'confidence', 'good', 'thing.|||i', 'cherish', 'time', 'solitude', 'b/c', 'revel', 'within', 'inner', 'world', 'whereas', 'time', \"i'd\", 'workin...', 'enjoy', 'time', 'can.', 'worry,', 'people', 'always', 'around', 'to...|||yo', 'entp', 'ladies...', 'complimentary', 'personality,well,', 'hey.|||...', 'main', 'social', 'outlet', 'xbox', 'live', 'conversations', 'even', 'verbally', 'fatigue', 'quickly.|||http://www.youtube.com/watch?v=gdhy7rdfm14', 'really', 'dig', 'part', '1:46', '2:50|||http://www.youtube.com/watch?v=msqxffgh7b8|||banned', 'thread', 'requires', 'me.|||get', 'high', 'backyard,', 'roast', 'eat', 'marshmellows', 'backyard', 'conversing', 'something', 'intellectual,', 'followed', 'massages', 'kisses.|||http://www.youtube.com/watch?v=mw7eou3bmbe|||http://www.youtube.com/watch?v=4v2uyorhqok|||http://www.youtube.com/watch?v=slvmgfqq0ti|||banned', 'many', \"b's\", 'sentence.', 'could', 'you!', 'think', 'b!|||banned', 'watching', 'movies', 'corner', 'dunces.|||banned', 'health', 'class', 'clearly', 'taught', 'nothing', 'peer', 'pressure.|||banned', 'whole', 'host', 'reasons!|||http://www.youtube.com/watch?v=ircrv41hgz4|||1)', 'two', 'baby', 'deer', 'left', 'right', 'munching', 'beetle', 'middle.', '2)', 'using', 'blood,', 'two', 'cavemen', 'diary', \"today's\", 'latest', 'happenings', 'designated', 'cave', 'diary', 'wall.', '3)', 'see', 'as...|||a', 'pokemon', 'world', 'infj', 'society', 'everyone', 'becomes', 'optimist|||49142|||http://www.youtube.com/watch?v=zrceq_jfefm|||http://discovermagazine.com/2012/jul-aug/20-things-you-didnt-know-about-deserts/desert.jpg|||http://oyster.ignimgs.com/mediawiki/apis.ign.com/pokemon-silver-version/d/dd/ditto.gif|||http://www.serebii.net/potw-dp/scizor.jpg|||not', 'artists', 'artists', 'draw.', 'idea', 'counts', 'forming', 'something', 'own...', 'like', 'signature.|||welcome', 'robot', 'ranks,', 'person', 'downed', 'self-esteem', 'cuz', \"i'm\", 'avid', 'signature', 'artist', 'like', 'herself.', ':proud:|||banned', 'taking', 'room', 'bed.', 'ya', 'gotta', 'learn', 'share', 'roaches.|||http://www.youtube.com/watch?v=w8igimn57aq|||banned', 'much', 'thundering,', 'grumbling', 'kind', 'storm...', 'yep.|||ahh...', 'old', 'high', 'school', 'music', 'heard', 'ages.', 'http://www.youtube.com/watch?v=dccrupcdb1w|||i', 'failed', 'public', 'speaking', 'class', 'years', 'ago', \"i've\", 'sort', 'learned', 'could', 'better', 'position', 'again.', 'big', 'part', 'failure', 'overloading', 'too...|||i', 'like', \"person's\", 'mentality.', \"he's\", 'confirmed', 'intj', 'way.', 'http://www.youtube.com/watch?v=hgkli-gec6m|||move', 'denver', 'area', 'start', 'new', 'life', \"myself.'\"]\n"
     ]
    }
   ],
   "source": [
    "texts, labels, max_seq_length, vocab_length, label_mapping = preprocess_inputs(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text sequences:\n",
      " (8675, 859)\n",
      "\n",
      "Labels:\n",
      " (8675,)\n",
      "\n",
      "Max sequence length:\n",
      " 859\n",
      "\n",
      "Vocab length:\n",
      " 10000\n",
      "\n",
      "Label mapping:\n",
      " {'INFJ': 0, 'ENTP': 1, 'INTP': 0, 'INTJ': 0, 'ENTJ': 1, 'ENFJ': 1, 'INFP': 0, 'ENFP': 1, 'ISFP': 0, 'ISTP': 0, 'ISFJ': 0, 'ISTJ': 0, 'ESTP': 1, 'ESFP': 1, 'ESTJ': 1, 'ESFJ': 1}\n"
     ]
    }
   ],
   "source": [
    "print(\"Text sequences:\\n\", texts.shape)\n",
    "print(\"\\nLabels:\\n\", labels.shape)\n",
    "print(\"\\nMax sequence length:\\n\", max_seq_length)\n",
    "print(\"\\nVocab length:\\n\", vocab_length)\n",
    "print(\"\\nLabel mapping:\\n\", label_mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "texts_train, texts_test, labels_train, labels_test = train_test_split(texts, labels, train_size=0.7, random_state=123)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "  6/152 [>.............................] - ETA: 18:36 - loss: 0.6691 - accuracy: 0.6298 - auc: 0.5457"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-26-6d6c2535f3f3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 36\u001b[0;31m history = model.fit(\n\u001b[0m\u001b[1;32m     37\u001b[0m     \u001b[0mtexts_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m     \u001b[0mlabels_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniforge3/envs/python38/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1098\u001b[0m                 _r=1):\n\u001b[1;32m   1099\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1100\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1101\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1102\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniforge3/envs/python38/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    826\u001b[0m     \u001b[0mtracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    827\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtrace\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtm\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 828\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    829\u001b[0m       \u001b[0mcompiler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"xla\"\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_experimental_compile\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"nonXla\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    830\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniforge3/envs/python38/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    853\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    854\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 855\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    856\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    857\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniforge3/envs/python38/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2940\u001b[0m       (graph_function,\n\u001b[1;32m   2941\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[0;32m-> 2942\u001b[0;31m     return graph_function._call_flat(\n\u001b[0m\u001b[1;32m   2943\u001b[0m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[1;32m   2944\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniforge3/envs/python38/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1916\u001b[0m         and executing_eagerly):\n\u001b[1;32m   1917\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1918\u001b[0;31m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0m\u001b[1;32m   1919\u001b[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[1;32m   1920\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n",
      "\u001b[0;32m~/miniforge3/envs/python38/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    553\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0m_InterpolateFunctionError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    554\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcancellation_manager\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 555\u001b[0;31m           outputs = execute.execute(\n\u001b[0m\u001b[1;32m    556\u001b[0m               \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    557\u001b[0m               \u001b[0mnum_outputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_outputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniforge3/envs/python38/lib/python3.8/site-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     57\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 59\u001b[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[1;32m     60\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "embedding_dim = 512\n",
    "\n",
    "inputs = tf.keras.Input(shape=(max_seq_length,))\n",
    "\n",
    "embedding = tf.keras.layers.Embedding(\n",
    "    input_dim=vocab_length,\n",
    "    output_dim=embedding_dim,\n",
    "    input_length=max_seq_length\n",
    ")(inputs)\n",
    "\n",
    "gru = tf.keras.layers.Bidirectional(\n",
    "    tf.keras.layers.GRU(\n",
    "        units=256,\n",
    "        return_sequences=True\n",
    "    )\n",
    ")(embedding)\n",
    "\n",
    "flatten = tf.keras.layers.Flatten()(gru)\n",
    "\n",
    "outputs = tf.keras.layers.Dense(1, activation='sigmoid')(flatten)\n",
    "\n",
    "\n",
    "model = tf.keras.Model(inputs, outputs)\n",
    "\n",
    "\n",
    "model.compile(\n",
    "    optimizer='adam',\n",
    "    loss='binary_crossentropy',\n",
    "    metrics=[\n",
    "        'accuracy',\n",
    "        tf.keras.metrics.AUC(name='auc')\n",
    "    ]\n",
    ")\n",
    "\n",
    "\n",
    "history = model.fit(\n",
    "    texts_train,\n",
    "    labels_train,\n",
    "    validation_split=0.2,\n",
    "    batch_size=32,\n",
    "    epochs=5,\n",
    "    callbacks=[\n",
    "        tf.keras.callbacks.ModelCheckpoint('./model.h5', save_best_only=True, save_weights_only=True)\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_weights('./model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.evaluate(texts_test, labels_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Every Day  \n",
    "\n",
    "This notebook is featured on Data Every Day, a YouTube series where I train models on a new dataset each day.  \n",
    "\n",
    "***\n",
    "\n",
    "Check it out!  \n",
    "https://youtu.be/s3g0MJcJZyA"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
