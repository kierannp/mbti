{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "import re\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "import tensorflow.keras.layers as layers\n",
    "from tensorflow.keras import Input\n",
    "import tensorflow_hub as hub\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "module_url = \"https://tfhub.dev/google/universal-sentence-encoder/4\"\n",
    "embedding_model = hub.load(module_url)\n",
    "def embed(input):\n",
    "    return embedding_model(input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"../data/mbti_1.csv\")\n",
    "sen_extra = []\n",
    "sen_posts = []\n",
    "sen_nature = []\n",
    "number_posts = 10\n",
    "types = pd.unique(data['type'])\n",
    "code = {tp:i for i,tp in enumerate(types)}\n",
    "rev_code  = {i:tp for i,tp in enumerate(types)}\n",
    "\n",
    "for index, row in data.iterrows(): \n",
    "    if len(row['posts'].split('|||')) < 10:\n",
    "        continue\n",
    "    embedded_posts = embed(row['posts'].split('|||')[:number_posts])\n",
    "    labels_extra = [(0 if 'E' in row['type'] else 1)] * number_posts\n",
    "    labels_nature = [(0 if 'T' in row['type'] else 1)] * number_posts\n",
    "    post = [post.numpy() for post in embedded_posts]\n",
    "    sen_extra.extend(labels_extra)\n",
    "    sen_nature.extend(labels_T)\n",
    "    sen_posts.extend(post)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "2436/2436 [==============================] - 4s 1ms/step - loss: 1.2071 - dense_73_loss: 0.5405 - dense_74_loss: 0.6666 - dense_73_accuracy: 0.7683 - dense_74_accuracy: 0.5893 - val_loss: 1.2016 - val_dense_73_loss: 0.5319 - val_dense_74_loss: 0.6697 - val_dense_73_accuracy: 0.7748 - val_dense_74_accuracy: 0.5978\n",
      "Epoch 2/10\n",
      "2436/2436 [==============================] - 4s 1ms/step - loss: 1.1787 - dense_73_loss: 0.5311 - dense_74_loss: 0.6476 - dense_73_accuracy: 0.7692 - dense_74_accuracy: 0.6259 - val_loss: 1.2046 - val_dense_73_loss: 0.5422 - val_dense_74_loss: 0.6625 - val_dense_73_accuracy: 0.7748 - val_dense_74_accuracy: 0.5973\n",
      "Epoch 3/10\n",
      "2436/2436 [==============================] - 3s 1ms/step - loss: 1.1687 - dense_73_loss: 0.5269 - dense_74_loss: 0.6418 - dense_73_accuracy: 0.7709 - dense_74_accuracy: 0.6320 - val_loss: 1.2008 - val_dense_73_loss: 0.5313 - val_dense_74_loss: 0.6695 - val_dense_73_accuracy: 0.7748 - val_dense_74_accuracy: 0.6021\n",
      "Epoch 4/10\n",
      "2436/2436 [==============================] - 3s 1ms/step - loss: 1.1467 - dense_73_loss: 0.5202 - dense_74_loss: 0.6265 - dense_73_accuracy: 0.7676 - dense_74_accuracy: 0.6494 - val_loss: 1.2090 - val_dense_73_loss: 0.5373 - val_dense_74_loss: 0.6717 - val_dense_73_accuracy: 0.7734 - val_dense_74_accuracy: 0.5975\n",
      "Epoch 5/10\n",
      "2436/2436 [==============================] - 3s 1ms/step - loss: 1.1017 - dense_73_loss: 0.5031 - dense_74_loss: 0.5986 - dense_73_accuracy: 0.7710 - dense_74_accuracy: 0.6760 - val_loss: 1.2226 - val_dense_73_loss: 0.5431 - val_dense_74_loss: 0.6794 - val_dense_73_accuracy: 0.7686 - val_dense_74_accuracy: 0.5909\n",
      "Epoch 6/10\n",
      "2436/2436 [==============================] - 3s 1ms/step - loss: 1.0447 - dense_73_loss: 0.4752 - dense_74_loss: 0.5695 - dense_73_accuracy: 0.7831 - dense_74_accuracy: 0.7029 - val_loss: 1.2864 - val_dense_73_loss: 0.5712 - val_dense_74_loss: 0.7152 - val_dense_73_accuracy: 0.7697 - val_dense_74_accuracy: 0.5900\n",
      "Epoch 7/10\n",
      "2436/2436 [==============================] - 3s 1ms/step - loss: 0.9839 - dense_73_loss: 0.4456 - dense_74_loss: 0.5383 - dense_73_accuracy: 0.7975 - dense_74_accuracy: 0.7276 - val_loss: 1.3136 - val_dense_73_loss: 0.5755 - val_dense_74_loss: 0.7381 - val_dense_73_accuracy: 0.7583 - val_dense_74_accuracy: 0.5854\n",
      "Epoch 8/10\n",
      "2436/2436 [==============================] - 4s 1ms/step - loss: 0.9278 - dense_73_loss: 0.4189 - dense_74_loss: 0.5090 - dense_73_accuracy: 0.8096 - dense_74_accuracy: 0.7493 - val_loss: 1.3622 - val_dense_73_loss: 0.5784 - val_dense_74_loss: 0.7838 - val_dense_73_accuracy: 0.7602 - val_dense_74_accuracy: 0.5774\n",
      "Epoch 9/10\n",
      "2436/2436 [==============================] - 4s 1ms/step - loss: 0.8702 - dense_73_loss: 0.3889 - dense_74_loss: 0.4813 - dense_73_accuracy: 0.8263 - dense_74_accuracy: 0.7648 - val_loss: 1.3772 - val_dense_73_loss: 0.6377 - val_dense_74_loss: 0.7395 - val_dense_73_accuracy: 0.7390 - val_dense_74_accuracy: 0.5745\n",
      "Epoch 10/10\n",
      "2436/2436 [==============================] - 4s 1ms/step - loss: 0.8225 - dense_73_loss: 0.3624 - dense_74_loss: 0.4601 - dense_73_accuracy: 0.8376 - dense_74_accuracy: 0.7795 - val_loss: 1.5388 - val_dense_73_loss: 0.6856 - val_dense_74_loss: 0.8533 - val_dense_73_accuracy: 0.7012 - val_dense_74_accuracy: 0.5754\n"
     ]
    }
   ],
   "source": [
    "embedding_dim = 512\n",
    "\n",
    "inputs = tf.keras.Input(shape=(embedding_dim,))\n",
    "\n",
    "dense1_1 = layers.Dense(512, activation=\"relu\")(inputs)\n",
    "drop1_1 = layers.Dropout(.2)(dense1_1)\n",
    "dense1_2 = layers.Dense(256, activation='relu')(drop1_1)\n",
    "drop1_2 = layers.Dropout(.2)(dense1_2)\n",
    "dense1_3 = layers.Dense(64, activation=\"relu\")(drop1_2)\n",
    "drop1_3 = layers.Dropout(.2)(dense1_3)\n",
    "\n",
    "dense2_1 = layers.Dense(512, activation=\"relu\")(inputs)\n",
    "drop2_1 = layers.Dropout(.2)(dense2_1)\n",
    "dense2_2 = layers.Dense(256, activation='relu')(drop2_1)\n",
    "drop2_2 = layers.Dropout(.2)(dense2_2)\n",
    "dense2_3 = layers.Dense(64, activation=\"relu\")(drop2_2)\n",
    "drop2_3 = layers.Dropout(.2)(dense2_3)\n",
    "\n",
    "output1 = layers.Dense(1, activation='sigmoid')(drop1_3)\n",
    "output2 = layers.Dense(1, activation='sigmoid')(drop2_3)\n",
    "\n",
    "model = tf.keras.Model(inputs, outputs= [output1, output2])\n",
    "\n",
    "\n",
    "model.compile(\n",
    "    optimizer='adam',\n",
    "    loss=['binary_crossentropy','binary_crossentropy'],\n",
    "    metrics=[\n",
    "        'accuracy'\n",
    "    ]\n",
    ")\n",
    "\n",
    "history = model.fit(\n",
    "    np.stack(sen_posts),\n",
    "    [np.array(sen_extra),np.array(sen_nature)],\n",
    "    batch_size=32,\n",
    "    validation_split=.1,\n",
    "    epochs=10,\n",
    "    callbacks=[\n",
    "        tf.keras.callbacks.ModelCheckpoint('./sentence_multi_out_model.h5', save_best_only=True, save_weights_only=True)\n",
    "    ]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
